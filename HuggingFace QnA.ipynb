{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf1591f",
   "metadata": {},
   "source": [
    "## Q and A with hugging Face transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7a1818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "id = 'deepset/minilm-uncased-squad2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(id)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(id, from_pt=True)\n",
    "pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38fdad",
   "metadata": {},
   "source": [
    "The\n",
    "from_pt=True parameter converts the weights to TensorFlow format. Itâ€™s not trivial to\n",
    "convert neural network weights from one format to another, but the Hugging Face\n",
    "library reduces it to a simple function parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeb5fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2790775001049042,\n",
       " 'start': 0,\n",
       " 'end': 27,\n",
       " 'answer': 'Natural Language Processing'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Define NLP'\n",
    "\n",
    "context = 'Natural Language Processing, or NLP, encompasses a variety of ' \\\n",
    "    'activities, including text classification, keyword and topic ' \\\n",
    "    'extraction, text summarization, and language translation. The ' \\\n",
    "    'accuracy of NLP models has improved in recent years for a variety ' \\\n",
    "    'of reasons, not the least of which are newer and better ways of ' \\\n",
    "    'converting words and sentences into dense vector representations ' \\\n",
    "    'that incorporate context, and a relatively new neural network ' \\\n",
    "    'architecture called the transformer that can zero in on the most ' \\\n",
    "    'meaningful words and even differentiate between multiple meanings ' \\\n",
    "    'of the same word.'\n",
    " \n",
    "pipe(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f418578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'When was TensorFlow released?'\n",
    "context = 'Machine learning isn\\'t hard when you have a properly ' \\\n",
    " 'engineered dataset to work with. The reason it\\'s not ' \\\n",
    " 'hard is libraries such as Scikit-Learn and ML.NET, which ' \\\n",
    " 'reduce complex learning algorithms to a few lines of code. ' \\\n",
    " 'Deep learning isn\\'t difficult, either, thanks to libraries ' \\\n",
    " 'such as the Microsoft Cognitive Toolkit (CNTK), Theano, and ' \\\n",
    " 'PyTorch. But the library that most of the world has settled ' \\\n",
    " 'on for building neural networks is TensorFlow, an open source ' \\\n",
    "     'framework created by Google that was released under the ' \\\n",
    " 'Apache License 2.0 in 2015.'\n",
    " \n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a557efb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all about neural networks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'How was Keras related to TensorFlow?'\n",
    "context = 'The learning curve for TensorFlow is rather steep. ' \\\n",
    " 'Another library, named Keras, provides a simplified ' \\\n",
    " 'Python interface to TensorFlow and has emerged as the ' \\\n",
    " 'Scikit of deep learning. Keras is all about neural networks. ' \\\n",
    " 'It began life as a standalone project in 2015 but was ' \\\n",
    " 'integrated into TensorFlow in 2019. Any code that you write ' \\\n",
    " 'using TensorFlow\\'s built-in Keras module ultimately executes ' \\\n",
    " 'in (and is optimized for) TensorFlow. Even Google recommends ' \\\n",
    " 'using the Keras API.'\n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keras'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Is it better to use Keras or TensorFlow to build neural networks?'\n",
    "pipe(question=question, context=context)['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e05fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
